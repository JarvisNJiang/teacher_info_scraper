# 项目路线图

## 短期目标（1-2个月内）
- [ v0.3.x ] 优化当前流程
    - 已知问题：
    - [ ] json文件中包含名字为空、或偶尔包括邮箱、公司名、列表字符等，逐步处理。
    - [ ] 教师列表存在翻页时，更好地输入逻辑
    - [ ] 多文件处理时容易卡死
    - [ ] 没有对报错文件单独记录、结合上一个问题可以考虑跳过错误文件然后记录
    - [ ] 增加一键处理，输入信息直接输出excel

- [ v0.4.x ] 实现对教师列表网站的批量管理
    - 功能列表：
    - [ ] 初步探索数据库，可以对教师列表信息进行导入、存储、查询、修改。
    - [ ] 进行数据库清洗：可以去重、去无意义内容
    - [ ] 前端实时显示已完成的学校状态
    - [ ] 实现动态更新、断点续传

- [ v0.5.0 ] 增加xpath辅助提取功能
    - 功能列表：
    - 识别各种类型的xpath（列表、照片墙（点名字跳转和点图片跳转双逻辑）、名单、）
    - 辅助定位xpath

- [ v0.6.0 ] 正式上线前的修补版本
    - 功能列表：
    - 

## 中期目标（3-6个月内）
- [ ] 覆盖更多教师信息类型（ocr处理图片类、解析pdf类）
- [ ] 执行更多任务（例如爬取学校联系方式）
- [ ] 定位包含特定信息的学校子级页面

## 长期愿景
- 打造一个灵活的高校老师知识库管理系统
- 通过大语言模型实现各项功能
- 专注于隐私保护

## 未来可能的功能
- 


## 简历内容的处理

动态内容：
某些网页可能使用JavaScript动态加载内容。我们的当前方法只处理静态HTML，可能会遗漏这些动态加载的内容。
iframe内容：
虽然我们移除了iframe标签，但有些重要内容可能嵌套在iframe中。我们可能需要考虑如何处理这些情况。
自定义标签：
一些网站可能使用自定义HTML标签来组织内容，这些可能被我们的处理逻辑忽略。
多语言支持：
如果网页包含多种语言的内容，我们可能需要考虑如何正确处理不同语言的文本。
特殊字符和编码：
某些特殊字符或非标准编码可能没有被正确处理。
嵌套结构：
复杂的嵌套HTML结构可能导致一些内容被错误地删除或保留。
注释中的内容：
HTML注释中可能包含有用信息，但当前逻辑会忽略这些。
隐藏元素：
使用CSS隐藏的元素（如display:none）可能包含有用信息，但可能被忽略。
非标准的内容标识：
一些网站可能使用非常规的类名或ID来标识主要内容，这些可能被我们的过滤规则误删。
分页内容：
如果教师信息跨多个页面，我们当前的方法可能只能处理单个页面。
元数据：
页面的<meta>标签可能包含有用的信息，但当前可能被忽略。
表格数据：
虽然我们保留了表格标签，但可能需要特殊处理来确保表格数据的结构完整性。
链接文本：
一些重要信息可能以链接形式出现，我们可能需要考虑如何处理这些链接文本。
图片alt文本：
图片的alt属性可能包含有用的描述信息，但可能被当前逻辑忽略。
非HTML内容：
PDF文件或其他文档格式的链接可能包含重要信息，但当前无法处理。

非常好，让我们探讨一下这三种情况的潜在处理方法：

分页内容处理：
潜在处理方法：
a) 检测分页链接：

在当前页面中查找常见的分页模式，如"下一页"、"2", "3", "4"等链接。
使用正则表达式或特定的HTML结构模式来识别这些链接。
b) 递归抓取：

对发现的分页链接进行递归抓取。
将每个页面的内容合并到一个完整的文档中。
c) 实现示例：

python

复制
def handle_pagination(url, base_content):
    all_content = base_content
    next_page = find_next_page_link(base_content)
    while next_page:
        next_content = fetch_webpage(next_page)
        all_content += preprocess_content(next_content)
        next_page = find_next_page_link(next_content)
    return all_content

def find_next_page_link(content):
    # 实现查找下一页链接的逻辑
    pass
图片信息处理：
潜在处理方法：
a) 提取alt文本：

保留图片的alt属性文本，这通常包含图片的描述信息。
b) 图片文件名分析：

分析图片的文件名，可能包含有用的关键词。
c) 图片周围文本：

提取图片标签周围的文本，可能包含与图片相关的描述。
d) 实现示例：

python

复制
def handle_images(soup):
    image_info = []
    for img in soup.find_all('img'):
        alt_text = img.get('alt', '')
        file_name = img.get('src', '').split('/')[-1]
        surrounding_text = img.parent.get_text(strip=True)
        image_info.append(f"Image: {alt_text} | File: {file_name} | Context: {surrounding_text}")
    return '\n'.join(image_info)
PDF文件处理：
潜在处理方法：
a) 提取PDF链接：

识别指向PDF文件的链接。
b) 下载和解析PDF：

使用库如PyPDF2或pdfminer来下载和解析PDF内容。
c) 整合PDF内容：

将解析出的PDF内容整合到主要的文本内容中。
d) 实现示例：

python

复制
import requests
from PyPDF2 import PdfReader
from io import BytesIO

def handle_pdf_links(soup, base_url):
    pdf_content = []
    for link in soup.find_all('a', href=lambda href: href and href.endswith('.pdf')):
        pdf_url = urljoin(base_url, link['href'])
        pdf_text = extract_pdf_content(pdf_url)
        pdf_content.append(f"PDF Content from {pdf_url}:\n{pdf_text}")
    return '\n\n'.join(pdf_content)

def extract_pdf_content(pdf_url):
    response = requests.get(pdf_url)
    pdf = PdfReader(BytesIO(response.content))
    return '\n'.join(page.extract_text() for page in pdf.pages)
实施这些方法时需要注意：

性能影响：特别是处理分页和PDF时，可能会显著增加处理时间。
错误处理：需要健壮的错误处理机制，特别是在网络请求和文件解析过程中。
内容相关性：确保提取的额外内容确实与教师简历相关。
法律和道德考虑：确保你有权限访问和处理这些额外的内容。
这些方法提供了处理这三种情况的基本框架。根据具体需求，您可能需要进一步调整和优化这些方法。您对这些建议有什么想法吗？或者您希望在某个特定方面深入探讨？


## 文本清洗

语言识别：
考虑添加语言识别功能。如果网页包含多种语言，可以根据主要语言选择合适的清理策略。
编码处理：
确保正确处理各种字符编码，特别是对于包含特殊字符或非ASCII字符的内容。
实体字符转换：
HTML实体字符（如  , & 等）可能没有被完全转换。可以考虑添加一个专门的步骤来处理这些实体字符。
保留更多语义结构：
考虑保留更多的语义结构，如列表（<ul>, <ol>）和表格（<table>）。这些结构对于简历格式可能很重要。
处理嵌套标签：
确保正确处理深度嵌套的HTML结构，避免丢失重要信息。
缩写和首字母缩略词处理：
考虑如何处理常见的缩写和首字母缩略词，确保它们不被错误地分割或修改。
数字和日期格式：
保护特定格式的数字和日期，这在简历中可能很重要（如电话号码、出生日期等）。
链接处理：
决定如何处理文本中的链接。是保留完整的URL，还是只保留链接文本，或是完全移除。
特殊符号处理：
某些特殊符号（如学位符号 °）可能需要特殊处理以确保它们被正确保留。
文本规范化：
考虑是否需要进行文本规范化，如将全角字符转换为半角字符，或统一中文标点的使用。
换行符统一：
确保统一使用同一种换行符（\n, \r\n, 或 \r），以适应不同操作系统的差异。
空白字符处理：
除了常规的空格，还要考虑如何处理其他类型的空白字符，如制表符、非断行空格等。
文本去重：
有时网页可能包含重复的内容块，考虑添加去重逻辑。
保留重要的样式信息：
某些样式信息（如粗体、斜体）可能对理解内容很重要，考虑如何在纯文本中表示这些信息。
错别字和OCR错误处理：
如果源数据可能包含错别字或OCR错误，可以考虑添加一些基本的纠错逻辑。

## 参考

## 短期目标（1-2个月内）
- [ ] 优化用户登录流程
- [ ] 修复首页加载速度慢的问题
- [ ] 实现基础的数据分析功能

## 中期目标（3-6个月内）
- [ ] 开发移动端应用
- [ ] 重构后端代码，提高系统稳定性
- [ ] 增加用户自定义仪表盘功能

## 长期愿景
- 打造全平台一体化解决方案
- 引入人工智能辅助决策功能
- 扩展国际市场，支持多语言

## 已知问题
- 大文件上传偶尔失败 [问题 #123]
- 某些旧版浏览器兼容性问题 [问题 #456]

## 未来可能的功能
- 集成第三方支付系统
- 添加团队协作功能
- 实现实时数据同步

注：此路线图将根据项目进展和用户反馈定期更新。
最后更新日期：[在此输入日期]